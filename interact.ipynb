{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import demjson\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "# Local files\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT_FILE = 'byui-python-analysis-30a31cf00f2c.json'\n",
    "REPORT_REQUEST_FILE = 'report-request.json'\n",
    "\n",
    "START_DATE = '12/1/2019'\n",
    "END_DATE = '12/8/2019'\n",
    "PERIOD = '4D'\n",
    "\n",
    "REQUEST_ALL_PAGES = True\n",
    "REQUEST_ALL_PERIODS = True\n",
    "\n",
    "CACHE_FOLDER = './data/cache'\n",
    "REPORT_FOLDER = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initalize API with Service Account File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=['https://www.googleapis.com/auth/analytics.readonly'])\n",
    "service = build('analytics','v3', credentials=credentials)\n",
    "analytics = build('analyticsreporting', 'v4', credentials=credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in Report Request file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests = [] \n",
    "with open(REPORT_REQUEST_FILE) as f:\n",
    "    requests = demjson.decode(f.read())\n",
    "\n",
    "for request in requests:\n",
    "    if REQUEST_ALL_PAGES:\n",
    "        # Set page size to max, so that making less requests\n",
    "        request['pageSize'] = 100000\n",
    "    \n",
    "    # Don't need totals or ranges, so leave them out\n",
    "    request['hideTotals'] = True\n",
    "    request['hideValueRanges'] = True\n",
    "    \n",
    "    folder_name = os.path.join(CACHE_FOLDER, utils.hash_dict(request))\n",
    "    Path(folder_name).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-12-01 to 2019-12-04 report #1 page 1 of 6 (rows 0-100000 of 545566)\n",
      "2019-12-01 to 2019-12-04 report #1 page 2 of 6 (rows 100000-200000 of 545566)\n",
      "2019-12-01 to 2019-12-04 report #1 page 3 of 6 (rows 200000-300000 of 545566)\n",
      "2019-12-01 to 2019-12-04 report #1 page 4 of 6 (rows 300000-400000 of 545566)\n",
      "2019-12-01 to 2019-12-04 report #1 page 5 of 6 (rows 400000-500000 of 545566)\n",
      "2019-12-01 to 2019-12-04 report #1 page 6 of 6 (rows 500000-545566 of 545566)\n",
      "2019-12-05 to 2019-12-08 report #1 page 1 of 5 (rows 0-100000 of 425642)\n",
      "2019-12-05 to 2019-12-08 report #1 page 2 of 5 (rows 100000-200000 of 425642)\n",
      "2019-12-05 to 2019-12-08 report #1 page 3 of 5 (rows 200000-300000 of 425642)\n",
      "2019-12-05 to 2019-12-08 report #1 page 4 of 5 (rows 300000-400000 of 425642)\n",
      "2019-12-05 to 2019-12-08 report #1 page 5 of 5 (rows 400000-425642 of 425642)\n"
     ]
    }
   ],
   "source": [
    "for reqs in utils.each_period(requests, START_DATE, END_DATE, PERIOD):\n",
    "    for i, report in utils.each_page(analytics, reqs, CACHE_FOLDER):\n",
    "        \n",
    "        date_range = reqs[0]['dateRanges'][0]\n",
    "        num_rows = len(report.get('data').get('rows',[]))\n",
    "        total_rows = int(report.get('data').get('rowCount',0))\n",
    "        last_row = int(report.get('nextPageToken',total_rows))\n",
    "        page_size = reqs[i].get('pageSize',1000)\n",
    "        \n",
    "        print('{} to {} report #{} page {:.0f} of {:.0f} (rows {}-{} of {})'.format(\n",
    "            date_range['startDate'], date_range['endDate'], i+1,\n",
    "            np.ceil(last_row / page_size),\n",
    "            np.ceil(total_rows / page_size),\n",
    "            last_row-num_rows, last_row, total_rows\n",
    "        ))\n",
    "        \n",
    "        if('samplesReadCounts' in report.get('data')):\n",
    "            for read_count, space_size in zip(report.get('data').get('samplesReadCounts'), report.get('data').get('samplingSpaceSizes')):\n",
    "                print('sample rate: {:0.1%}  ({} / {})'.format(int(read_count) / int(space_size), read_count, space_size))\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = utils.report_to_frame(report)\n",
    "        \n",
    "        filename = os.path.join(\n",
    "            CACHE_FOLDER,\n",
    "            utils.hash_dict(requests[i]),\n",
    "            '{}_{:.0f}.csv'.format(date_range['startDate'],np.ceil(last_row / page_size)))\n",
    "        \n",
    "        df.to_csv(filename)\n",
    "        \n",
    "        if not REQUEST_ALL_PAGES:\n",
    "            break;\n",
    "    if not REQUEST_ALL_PERIODS:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Concatenate Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concatenating 11 reports\n",
      "writing report to \"./data/Jan17_2221_0.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Create Directory if doesn't exist\n",
    "Path(REPORT_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Get Current Time\n",
    "current_time = datetime.now().strftime(\"%h%d_%H%M\")\n",
    "\n",
    "for i, request in enumerate(requests):\n",
    "    files = glob(os.path.join(CACHE_FOLDER, utils.hash_dict(request), \"*.csv\"))\n",
    "    print('concatenating {} reports...'.format(len(files)))\n",
    "    df = pd.concat(map(pd.read_csv, files))\n",
    "    filename = os.path.join(REPORT_FOLDER, current_time+'_'+str(i)+'.csv')\n",
    "    print('writing report to \"{}\"'.format(filename))\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
